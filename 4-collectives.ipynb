{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e67c2c-18b5-4096-aecf-2ec5eb2ac3d4",
   "metadata": {},
   "source": [
    "# Communications collectives\n",
    "\n",
    "Les communications collectives peuvent faire :\n",
    "\n",
    "* des **déplacements de données**\n",
    "    * `MPI_Bcast`\n",
    "    * `MPI_Scatter`\n",
    "    * `MPI_Gather`, `MPI_Allgather`\n",
    "    * `MPI_Alltoall`\n",
    "* des **calculs collectifs**\n",
    "    * `MPI_Reduce`, `MPI_Allreduce`\n",
    "\n",
    "Chaque appel à ces fonctions doit être fait par\n",
    "**tous les processus d'un même communicateur**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e40adf-b44b-4c75-9f30-9bc541575e9e",
   "metadata": {},
   "source": [
    "## Déplacements de données\n",
    "\n",
    "### Diffusion de données avec `MPI_Bcast`\n",
    "\n",
    "Pour envoyer les mêmes informations à tous les processus d'un même\n",
    "communicateur, on utilise une fonction effectuant une **diffusion** :\n",
    "\n",
    "![Figure MPI_Bcast](images/mpi_bcast.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adacc112-9ee2-475d-bc0a-21df41dfffa8",
   "metadata": {},
   "source": [
    "[En **C**](https://www.mpi-forum.org/docs/mpi-4.1/mpi41-report.pdf#section.6.4) :\n",
    "\n",
    "```C\n",
    "// int MPI_Bcast(void *tampon, int compte, MPI_Datatype type,\n",
    "//               int racine, MPI_Comm comm)\n",
    "\n",
    "ierr = MPI_Bcast(&a, 1, MPI_INT, 2, MPI_COMM_WORLD);\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb555af-74e9-46ef-b3b1-cbf7e15129f6",
   "metadata": {},
   "source": [
    "[En **Python**](https://mpi4py.readthedocs.io/en/latest/reference/mpi4py.MPI.Comm.html#mpi4py.MPI.Comm.bcast) :\n",
    "\n",
    "```Python\n",
    "# bcast(objet: Any, racine: int = 0) -> Any\n",
    "\n",
    "a = comm.bcast(a, 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6254fec-a166-4eed-a17a-18019f4d1bd8",
   "metadata": {},
   "source": [
    "### Distribution de données avec `MPI_Scatter`\n",
    "\n",
    "Pour envoyer une portion des données à chaque\n",
    "processus d'un même communicateur, on utilise\n",
    "une fonction effectuant une **distribution** :\n",
    "\n",
    "![Figure MPI_Scatter](images/mpi_scatter.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58a4351-f5bf-40b1-929a-d56e9ee065c3",
   "metadata": {},
   "source": [
    "[En **C**](https://www.mpi-forum.org/docs/mpi-4.1/mpi41-report.pdf#section.6.6) :\n",
    "\n",
    "```C\n",
    "// int MPI_Scatter(\n",
    "//     void *envoi, int compte_envoi, MPI_Datatype type_envoi,\n",
    "//     void *recep, int compte_recep, MPI_Datatype type_recep,\n",
    "//     int racine, MPI_Comm comm)\n",
    "\n",
    "ierr = MPI_Scatter( a, 1, MPI_INT,\n",
    "                   &b, 1, MPI_INT, 2, MPI_COMM_WORLD);\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd74f45-f414-4651-9974-c8c74b470677",
   "metadata": {},
   "source": [
    "[En **Python**](https://mpi4py.readthedocs.io/en/latest/reference/mpi4py.MPI.Comm.html#mpi4py.MPI.Comm.scatter) :\n",
    "\n",
    "```Python\n",
    "# scatter(envoi: Sequence[Any] | None, racine: int = 0) -> Any\n",
    "\n",
    "b = comm.scatter(a, 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7242e737-c9d8-4210-ab19-ef894ed2414b",
   "metadata": {},
   "source": [
    "### Regroupement de données avec `MPI_Gather`\n",
    "\n",
    "Pour récupérer plusieurs portions de données\n",
    "dans un seul processus d'un communicateur, on\n",
    "utilise une fonction effectuant un **regroupement** :\n",
    "\n",
    "![Figure MPI_Gather](images/mpi_gather.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26d881-eb90-4ff6-b202-3e3f4ec0417e",
   "metadata": {},
   "source": [
    "[En **C**](https://www.mpi-forum.org/docs/mpi-4.1/mpi41-report.pdf#section.6.5) :\n",
    "\n",
    "```C\n",
    "// int MPI_Gather(\n",
    "//     void *envoi, int compte_envoi, MPI_Datatype type_envoi,\n",
    "//     void *recep, int compte_recep, MPI_Datatype type_recep,\n",
    "//     int racine, MPI_Comm comm)\n",
    "\n",
    "ierr = MPI_Gather(&a, 1, MPI_INT,\n",
    "                   b, 1, MPI_INT, 2, MPI_COMM_WORLD);\n",
    "\n",
    "```\n",
    "\n",
    "[En **Python**](https://mpi4py.readthedocs.io/en/latest/reference/mpi4py.MPI.Comm.html#mpi4py.MPI.Comm.gather) :\n",
    "\n",
    "```Python\n",
    "# gather(envoi: Any, racine: int = 0) -> list[Any] | None\n",
    "\n",
    "b = comm.gather(a, 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7085b5e-bf34-48b3-ba80-f2e3d9de1fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
